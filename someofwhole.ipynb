{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라벨 데이터 선별작업\n",
    "\n",
    "AI-hub에 업로드 된 데이터셋의 크기가 너무 크고   \n",
    "영상의 중복이 크기 때문에 약 421기가 크기의 화재 영상,라벨 데이터셋을   \n",
    "약 50기가 크기의 데이터셋으로 줄이기 위함.   \n",
    "random함수를 통해 약 12~13%의 데이터만 랜덤적으로 선별.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[라벨]화재씬.zip안의 .json 파일의 갯수는 533159개 입니다.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "parse_dir_list = ['C','S','N']\n",
    "parse_file_list = ['[라벨]화재씬.zip','[라벨]유사씬.zip','[라벨]무관씬.zip']\n",
    "whole_label_path = 'C:/Users/aischool/Downloads/화재 발생 예측 영상/Training'\n",
    "label_dir_path = 'C:/Users/aischool/OneDrive/Desktop/최종프로젝트/dataset/labels'\n",
    "image_dir_path = 'C:/Users/aischool/OneDrive/Desktop/최종프로젝트/dataset/images'\n",
    "\n",
    "my_zip_list = []\n",
    "my_json_list = []\n",
    "for z_file in parse_file_list:\n",
    "    try:\n",
    "        my_zip = zipfile.ZipFile(os.path.join(whole_label_path,z_file))\n",
    "        my_zip_list.append(my_zip)\n",
    "        json_list = np.array(my_zip.namelist())\n",
    "        my_json_list.append(json_list)\n",
    "        print(f'{z_file}안의 .json 파일의 갯수는 {len(json_list)}개 입니다.')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(my_zip_list)):\n",
    "    if not os.path.exists(label_dir_path + str(i)):\n",
    "        os.makedirs(label_dir_path + str(i))\n",
    "    for filename in my_json_list[i]:\n",
    "        if random.random() < 0.005:\n",
    "            my_zip_list[i].extract(filename, label_dir_path + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json file to txt file for YOLO\n",
    "\n",
    "json형식으로 저장된 라벨 데이터를 YOLO모델 학습에 적합한 txt파일로 변환하는 과정   \n",
    "box형식과 polygon형식으로 저장된 라벨 데이터를 변환하여   \n",
    "전부 box형식의 라벨 데이터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "for root, dirs, filenames in os.walk('C:/Users/aischool/OneDrive/Desktop/최종프로젝트'):\n",
    "    for filename in filenames:\n",
    "        txt = []\n",
    "        if '.json' in filename:\n",
    "            data = json.load(open(os.path.join(root,filename),'r',encoding='utf-8'))\n",
    "            i_w = data['image']['resolution'][0]\n",
    "            i_h = data['image']['resolution'][1]\n",
    "            f = open(os.path.join(root,filename.replace('.json','.txt')),'a')\n",
    "            for v in data['annotations']:\n",
    "                if 'box' in v:\n",
    "                    l = np.array(v['box'])\n",
    "                    try:\n",
    "                        cx,cy,w,h = ((l[0]+l[2])/2/i_w,(l[1]+l[3])/2/i_h , (l[2]-l[0])/i_w , (l[3]-l[1])/i_h)\n",
    "                        write_str = str(int(v['class']) - 1)+ ' ' + str(cx.round(6)) + ' ' + str(cy.round(6)) + ' '  + str(w.round(6)) +  ' ' + str(h.round(6)) + '\\n'\n",
    "                        if write_str not in txt:\n",
    "                            txt.append(write_str)\n",
    "                    except:\n",
    "                        print(filename)\n",
    "                elif 'polygon' in v:\n",
    "                    l = np.array(v['polygon'])\n",
    "                    try:\n",
    "                        maxs = np.max(l,axis=0)\n",
    "                        mins = np.min(l,axis=0)\n",
    "                        cx = (maxs[0] + mins[0]) / 2 / i_w\n",
    "                        cy = (maxs[1] + mins[1]) / 2 / i_h\n",
    "                        w = (maxs[0] - mins[0]) / i_w\n",
    "                        h = (maxs[1] - mins[1]) / i_h\n",
    "                        # print(maxs[0], mins[0], maxs[0], mins[1])\n",
    "                        # print(cx,cy,w,h)\n",
    "                        write_str = str(int(v['class']) - 1)+ ' ' + str(cx.round(6)) + ' ' + str(cy.round(6)) + ' '  + str(w.round(6)) +  ' ' + str(h.round(6)) + '\\n'\n",
    "                        if write_str not in txt:\n",
    "                            txt.append(write_str)\n",
    "                    except:\n",
    "                        print(filename)\n",
    "            for v in txt:\n",
    "                f.write(v)\n",
    "            f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 데이터 선별작업\n",
    "\n",
    "앞서 진행했던 라벨 데이터 선별작업을 통해 라벨 데이터는 선별 작업이 끝난 상태   \n",
    "이제 이미지 데이터에 대한 선별 작업을 진행해야 하는데   \n",
    "이미지 데이터 선별 작업의 근거는 앞서 진행했던 라벨 데이터를 기준으로 이미지에 대한 라벨의 존재 여부이다.   \n",
    "이미지에 대한 라벨이 존재하는 경우 압축파일에서 압축 해제를 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_labeled_list = []\n",
    "for root, dirs, filenames in os.walk('C:/Users/aischool/OneDrive/Desktop/최종프로젝트/dataset'):\n",
    "    labeled_list = [] #이미지 데이터 선별 작업의 근거가 될 리스트\n",
    "    for filename in filenames:\n",
    "        if '.txt' in filename:\n",
    "            labeled_list.append(filename.replace('.txt','.jpg'))\n",
    "    if len(labeled_list) > 0:\n",
    "        my_labeled_list.append(labeled_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[원천]화재씬.zip\n",
      "[원천]화재씬_1.zip\n",
      "[원천]화재씬_10.zip\n",
      "[원천]화재씬_11.zip\n",
      "[원천]화재씬_12.zip\n",
      "[원천]화재씬_13.zip\n",
      "[원천]화재씬_2.zip\n",
      "[원천]화재씬_3.zip\n",
      "[원천]화재씬_4.zip\n",
      "[원천]화재씬_5.zip\n",
      "[원천]화재씬_6.zip\n",
      "[원천]화재씬_7.zip\n",
      "[원천]화재씬_8.zip\n",
      "[원천]화재씬_9.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import numpy as np\n",
    "for i in range(len(my_labeled_list)):\n",
    "    for root, dirs, filenames in os.walk('C:/Users/aischool/Downloads/화재 발생 예측 영상/Training'):\n",
    "        for filename in filenames:\n",
    "            if '.zip' in filename and '[원천]' in filename:\n",
    "                print(filename)\n",
    "                jpg_zip = zipfile.ZipFile(os.path.join(root,filename))\n",
    "                jpg_list = np.array(jpg_zip.namelist())\n",
    "                for jpg_name in jpg_list:\n",
    "                    if jpg_name in my_labeled_list[i]:\n",
    "                        try:\n",
    "                            jpg_zip.extract(jpg_name, image_dir_path + str(i)) #'Bad magic number for file header' 오류 발생으로 인한 예외사항 지정\n",
    "                        except:\n",
    "                            pass\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, t_filenames in os.walk('C:/Users/aischool/OneDrive/Desktop/최종프로젝트/dataset'):\n",
    "    for t_filename in t_filenames:\n",
    "        if '.txt' in t_filename:\n",
    "            if not os.path.isfile(os.path.join(root.replace('labels','images'), t_filename.replace('.txt','.jpg'))):\n",
    "                os.remove(os.path.join(root,t_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 나누기\n",
    "\n",
    "이미지-라벨 데이터셋을 train, valid, test = 7:2:1 비율로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "dir_parse_list1 = ['train','valid','test']\n",
    "dir_parse_list2 = ['images','labels']\n",
    "\n",
    "for dpl1 in dir_parse_list1:\n",
    "    for dpl2 in dir_parse_list2:\n",
    "        for i in range(len(my_json_list)):\n",
    "            if not os.path.exists('C:/Users/aischool/OneDrive/Desktop/최종프로젝트/dataset/dataset_' + str(i) + '/' + dpl1 + '/' + dpl2):\n",
    "                os.makedirs('C:/Users/aischool/OneDrive/Desktop/최종프로젝트/dataset/dataset_' + str(i) + '/' + dpl1 + '/' + dpl2)\n",
    "\n",
    "for i in range(len(parse_file_list)):\n",
    "    for root, dirs, filenames in os.walk('C:/Users/aischool/OneDrive/Desktop/최종프로젝트/dataset/images' + str(i)):\n",
    "        for filename in filenames:\n",
    "            if random.random() < 0.7:#train : valid : test = 7 : 2 : 1dataset_'+str(i)+'\n",
    "                shutil.move(os.path.join(root,filename), os.path.join(root[:-1].replace('dataset','dataset/dataset_'+str(i)+'/train'), filename))\n",
    "                shutil.move(os.path.join(root.replace('images','labels'), filename.replace('.jpg','.txt')), os.path.join(root[:-1].replace('dataset/images','dataset/dataset_'+str(i)+'/train/labels'), filename.replace('.jpg','.txt')))\n",
    "            else:    \n",
    "                if random.random() < 0.66: #valid\n",
    "                    shutil.move(os.path.join(root,filename), os.path.join(root[:-1].replace('dataset','dataset/dataset_'+str(i)+'/valid'), filename))\n",
    "                    shutil.move(os.path.join(root.replace('images','labels'), filename.replace('.jpg','.txt')), os.path.join(root[:-1].replace('dataset/images','dataset/dataset_'+str(i)+'/valid/labels'), filename.replace('.jpg','.txt')))\n",
    "                else: #test\n",
    "                    shutil.move(os.path.join(root,filename), os.path.join(root[:-1].replace('dataset','dataset/dataset_'+str(i)+'/test'), filename))\n",
    "                    shutil.move(os.path.join(root.replace('images','labels'), filename.replace('.jpg','.txt')), os.path.join(root[:-1].replace('dataset/images','dataset/dataset_'+str(i)+'/test/labels'), filename.replace('.jpg','.txt')))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python \"C:/Users/aischool/OneDrive/Desktop/최종프로젝트/yolov7/train.py\" --weights  yolov7-w6.pt --data \"data/fire.yaml\" --cfg cfg/training/fire.yaml --name fire --hyp data/hyp.scratch.custom.yaml --cache-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72b390188645abf6f0380eaf0d3805bc6e25a3b3a0701380d99b72735eda6e38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
